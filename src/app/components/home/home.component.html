<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container-fluid">

    <!--heading on the nav bar-->
    <p class="navbar-header pull-left">
      <a href=""
         class="navbar-brand thick">
        <b>Rahul Kondakrindi</b>
      </a>
    </p>

    <!-- github icon -->
    <p class="navbar-text pull-right">
      <a href="https://github.com/rahulm8"
         class="navbar-link">
        <span class="fa fa-github-square fa-3x"></span>
      </a>
    </p>

    <!-- linkedin icon -->
    <p class="navbar-text pull-right">
      <a href="https://www.linkedin.com/in/rahul-kondakrindi-11433112b/"
         class="navbar-link">
        <span class="fa fa-linkedin-square fa-3x"></span>
      </a>
    </p>

    <!-- mail icon -->
    <p class="navbar-text pull-right">
      <a href="https://angel.co/rahul-kondakrindi"
         class="navbar-link">
        <span class="fa fa-angellist fa-3x"></span>
      </a>
    </p>


  </div>
</nav>

<div class="container-fluid">

  <img class="rk-content" width="100%" height="600" src="https://i.imgur.com/LcdKZjo.jpg"/>

  <h1>About Me</h1>
  <b>Hey there!! I am Computer Science Graduate
    Student at Northeastern University.
    I have previously worked as data analyst intern at
    Einsite, Hyderabad. I consider myself good at data
    analysis with experience in python, R. I'm also learning
    full stack web development as world wide web is
    the origin for most of the data. When I'm not coding,
    I read non-fiction books. I am also very passionate
    about fitness and nutrition.</b>

  <h1>Projects</h1>
  <ul class="list-group">
    <li class="list-group-item">
      <a href="https://logdownproject.herokuapp.com/">
        <h2>LogDown</h2>
      </a><br>
      <b>LogDown enables users to search the caloric
        content and other details in a particular food
        item and add them to their daily food log by
        using the Nutrionix API. This application
        was developed using MEAN stack. </b>
    </li>
    <li class="list-group-item">
      <a href="https://webdev-kondakrindi-rahul.herokuapp.com/">
        <h2>WebAppMaker</h2>
      </a><br>
      <b>WebAppMaker is a Single Page Application developed using MEAN stack,
        for users to create and customize websites.</b>
    </li>
    <li class="list-group-item">
      <a href="https://github.com/rahulm8/United-States-Obesity-Risk-Factors-Analysis">
        <h2>United States Obesity Risk Factor Analysis</h2>
      </a><br>
      <b>Compiled state-wise data on obesity risk factors
        and demographic factors across the entire US
        population. Performed clustering on each data-set
        using techniques like K-Means, Agglomerative
        Hierarchical clustering, DB-SCAN. Visualized and
        compared clustered data-sets by plotting the
        data onto choropleth maps of US States.</b>
    </li>
    <li class="list-group-item">
      <a href="https://github.com/rahulm8/ThemeExtractor">
        <h2>Theme Extractor</h2>
      </a><br>
      <b>Developed an application to extract the theme
        of a sentence by using Dependency Parser which
        is pre-trained using TreeBanks. Dependency parser
        finds the dependencies among the various words
        present in a sentence. TreeBank is a parsed text
        corpus that annotates syntactic or semantic sentence
        structure. </b>
    </li>
    <li class="list-group-item">
      <a href="https://github.com/rahulm8/Search-Engine">
        <h2>Topic Based Search Engine</h2>
      </a><br>
      <b>A custom search engine was built to retrieve
        information from a corpus made up of 1000 unique
        wikipedia urls. The retrieval models implemented
        in the search engine are TF-IDF, BM25 ranking
        algorithm and LUCENE. Techniques like stopping,
        stemming and query expansion using psuedo relevance
        feedback were used to improve the performance of the
        retrieval model. The retrieval models were evaluated using
        techniques like Precision, Recall, MAP, MRR.</b>
    </li>
  </ul>

  <h1>Work</h1>
  <h3>Data Analyst Intern, Einsite</h3>
  <ul>
    <li><b>Built an application to analyse a transaction record.
      Visual validation is done by generating the paths
      in google maps for all the unique assets that satisfy
      the transaction constraints . The application was
      developed in Python and the prominent library used
      is Pandas.</b> </li>
    <li><b>Created a python script to match the Master BOQs'
      (Bill of Quantities) with the Project BOQs'.
      The matching was implemented using the idea of TF-iDF.
      SpaCy, an industrial strength NLP library has
      also been utilized for this task.</b></li>
    <li><b>Incorporated the AutoComplete feature to capture
      the work executed in the Einsite suite of applications
      using Tries. </b></li>
  </ul>


</div>


<nav class="navbar navbar-default navbar-fixed-bottom">
  <div class="container-fluid"></div>
</nav>
